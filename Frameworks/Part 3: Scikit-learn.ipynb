{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn machine learning in Natural Language Processing\n",
    "Machine learning becomes an irreplaceble tool to create smart applications and it empowers some of the most impressive modern applications that we take for granted: YouTube, Spotify, Amazon, Google, etc. In this notebook I will explain the basics of machine learning and how linguists can make a difference with it.  \n",
    "\n",
    "# Introduction into machine learning\n",
    "Machine learning is a whole branch of computer science devoted to solve problems that ordinary computing cannot. There's a whole range of tasks that require *flexibility*, from image detection to machine translation, that cannot be hardcoded with algorithms. These sorts of problems require a degree of abstract thinking and subtle experience. In such domains as *image detection*, software needs to identify different fragments in the picture and tell apart different classes of beings, which requires knowing how those objects can look like to compare against.  \n",
    "\n",
    "The way how machine learning works is by making a prediction, and whenever the model makes a mistake, it measures its error and remembers it so that next time it's more accurate. With time, when it is fed with a lot of data, it becomes accurate enough to be used in production. Under the hood it just plugs values (known as parameters) into a formula, and when model corrects itself, it adjusts its parameters. At the end, the model is nothing more than a long tree of parameters that need to be plugged into a formula to make a prediction in the release conditions.  \n",
    "\n",
    "There are 3 sorts of machine learning. In the first one, **supervised learning**, the data the model learns from is labelled, and the model is restricted only to output one of the classes it is fed with. Predictions and detection are some of its primary applications. In **unsupervised learning**, however, there are no labels and predetermined output too, so the model must come up with its own output. It is used for classification and creative tasks. Finally, in **reinforcement learning** there is no input nor output, but the model controls an agent that exists in a virtual environment where it needs to accomplish a specific task. In most cases, it happens as machine learning how to play computer games. The process of learning works by trying out random things and whenever it succeeds, it gets *reward*. The model then remembers this particular action led it to reward and the whole task is to maximize it.  \n",
    "\n",
    "Aside from those three, there's a forth way that can be mixed with those, **deep learning**. It deals with *neural networks*, a way to make decisions based on a variable sequence of paths. Neural networks consist of layers of *nodes* that accept a value and each node is connected with nodes from the next layer. In the most primitive example, a network can have just 2 layers: one takes input and the other one represents the output. When value is passed to the next nodes, it is modified with a special algorithm that the connected node receives. At the end, the one node that got the biggest value is the result of processing. However, in most cases there are plenty hidden layers between those two that keep processing data.  \n",
    "\n",
    "# Getting started with Scikit-learn and sentimental analysis\n",
    "Machine learning deals with extensive mathematics and statistics. Luckily, developers do not need to implement all of those algorithms and data structures themselves to create their own artificial intelligence but can use a number of available frameworks. Python is known to be the powerhouse of TensorFlow, PyTorch, Keras, and today we will study Scikit-learn.   \n",
    "\n",
    "Machine learning is primarily about the data. The algorithms are there, and the task of data scientists is only to learn the frameworks and get data. As we know, machine learns by data, which means it is utmost greatest priority to first collect large enough data for our task.  \n",
    "\n",
    "One of the tasks where machine learning excels for linguists is the ability to match pieces of text by sentiment, which can span from product reviews to global political reception. Sentimental analysis is nothing more than a classification task.  \n",
    "\n",
    "Firstly, we need to gather data. I decided to build the model that will classify **food reviews**. Amazon has kindly shared its dataset that we can use on the public domain conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 93735",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_extraction\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m----> 8\u001b[0m reviews \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m/workspaces/linguistic-research/Sources/Reviews.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m reviews\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1765\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1766\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1767\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     (\n\u001b[1;32m   1769\u001b[0m         index,\n\u001b[1;32m   1770\u001b[0m         columns,\n\u001b[1;32m   1771\u001b[0m         col_dict,\n\u001b[0;32m-> 1772\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1773\u001b[0m         nrows\n\u001b[1;32m   1774\u001b[0m     )\n\u001b[1;32m   1775\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:243\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 243\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    244\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 93735"
     ]
    }
   ],
   "source": [
    "#Setting up ML workflow\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "reviews = pd.read_csv(\"/workspaces/linguistic-research/Sources/Reviews.csv\")\n",
    "reviews.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
